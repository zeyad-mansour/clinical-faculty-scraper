{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d66aabd-35b4-4b8a-9997-c73edf0b2f3f",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "Navigate to the list of faculty in the Anesthesiology Department (be aware that each website is very different. For instance, the links for Upstate and Westchester are already linked to the Anesthesiology program, but you will have to navigate to the faculty page; the New Mexico website has to be filtered first in order to see just the anesthesiology faculty). \n",
    "\n",
    "\n",
    "Once you find the appropriate pages with the faculty listed, I would like you to create an excel file, where each institution as its own sheet. There should be four headers for each sheet: First Name, Last Name, Email, Error. The first name and last name of a clinician should be in the appropriate cell as well as their email (if scrapable). Error should remain blank for now. There should not be any other text in the first name or last name columns (no MD, DO, or any titles, just a single name in each). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aaf0aac9-2e36-462d-bbd4-6adf02ca7300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /opt/homebrew/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: xlsxwriter in /opt/homebrew/lib/python3.11/site-packages (3.2.0)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytesseract in /opt/homebrew/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/homebrew/lib/python3.11/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from pytesseract) (10.0.1)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pillow in /opt/homebrew/lib/python3.11/site-packages (10.0.1)\n",
      "\u001b[33mWARNING: Skipping /opt/homebrew/lib/python3.11/site-packages/certifi-2024.2.2.dist-info due to invalid metadata entry 'name'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install xlsxwriter\n",
    "!pip install pytesseract\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f31e85e-7d6d-4553-b31d-80abdeac66d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from PIL import Image, ImageOps\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "221e85a5-d06f-4f2b-b787-48e1d0f9e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions\n",
    "\n",
    "def add_whitespace_border(image, border_size):\n",
    "    \"\"\"\n",
    "    Adds a whitespace border to an image.\n",
    "\n",
    "    Args:\n",
    "        image: PIL Image object.\n",
    "        border_size: Width of the border in pixels.\n",
    "\n",
    "    Returns:\n",
    "        PIL Image object with the added border.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    new_width = width + border_size * 2\n",
    "    new_height = height + border_size * 2\n",
    "\n",
    "    # Create a new white image with the larger size\n",
    "    bordered_image = Image.new(image.mode, (new_width, new_height), color='white')\n",
    "\n",
    "    # Paste the original image onto the new image with the border offset\n",
    "    bordered_image.paste(image, (border_size, border_size))\n",
    "\n",
    "    return bordered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c82b5d80-5eb2-4152-afcb-fb6956c877e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved UNM data to anesthesiology_faculty.xlsx\n",
      "Saved Upstate data to anesthesiology_faculty.xlsx\n",
      "Saved Westchester data to anesthesiology_faculty.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define URLs for each institution\n",
    "urls = {\n",
    "    \"UNM\": \"https://hsc.unm.edu/directory/index.json\",\n",
    "    \"Upstate\": \"https://www.upstate.edu/anesthesiology/about-us/faculty.php\",\n",
    "    \"Westchester\": \"https://www.westchestermedicalcenter.org/anesthesiology-residency-program\",\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store dataframes for each institution\n",
    "dfs = {}\n",
    "\n",
    "# Function to extract faculty information from a given URL\n",
    "def extract_faculty_data(url, institution_name):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    faculty_data = [] # Initialize an empty list to store data\n",
    "\n",
    "    if \"hsc.unm.edu\" in url:\n",
    "        # Logic for University of New Mexico\n",
    "        data = response.json()\n",
    "        \n",
    "        # Filter for Anesthesiology faculty\n",
    "        anesthesiology_faculty = [\n",
    "            faculty\n",
    "            for faculty in data[\"faculty\"]\n",
    "            if \"SOM - Anesthesiology\" in faculty.get(\"departments\", [])\n",
    "        ]\n",
    "        \n",
    "        # Extract and format data\n",
    "        faculty_data = []\n",
    "        for faculty in anesthesiology_faculty:\n",
    "            first_name = faculty[\"firstName\"].strip()\n",
    "            last_name = faculty[\"lastName\"].strip()\n",
    "            email = \"\"  # Email not available in this dataset\n",
    "            faculty_data.append([first_name, last_name, email, \"\"])\n",
    "\n",
    "\n",
    "    elif \"upstate.edu\" in url:\n",
    "        # Logic for Upstate Medical University\n",
    "        faculty_page = soup.find(\"div\", {\"id\": \"faculty_page\"})\n",
    "        \n",
    "        for link in faculty_page.find_all('a', href=True):\n",
    "            response = requests.get(url + link['href'])\n",
    "            person_page = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "            person_page = person_page.find(\"div\", {\"class\": \"block-email\"})\n",
    "            email_image_link = person_page.find(\"img\")[\"src\"]\n",
    "        \n",
    "            # Run OCR on image to extract email\n",
    "            email = \"\"\n",
    "            try:\n",
    "                # Download and read the image\n",
    "                image_data = requests.get(email_image_link).content\n",
    "                image = Image.open(BytesIO(image_data))\n",
    "                image = add_whitespace_border(image, border_size=10)  # Add 10px border\n",
    "                \n",
    "                # OCR with configuration\n",
    "                email = pytesseract.image_to_string(image, config='--psm 6')# Assume single line of text (email) \n",
    "                email = email.strip()  # Remove whitespace\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting email: {e}\")\n",
    "        \n",
    "            split_text = link.contents[0].split(\",\")\n",
    "            \n",
    "            if len(split_text) > 1:\n",
    "                full_name = split_text[0]\n",
    "                full_name = full_name.split(\".\")\n",
    "                if len(full_name) > 1:\n",
    "                    first_name = full_name[0] + \".\"\n",
    "                    last_name = full_name[-1]\n",
    "                    faculty_data.append([first_name.strip(), last_name.strip(), email.strip(), \"\"])\n",
    "                else:\n",
    "                    full_name = split_text[0].split(\" \")\n",
    "                    first_name = full_name[0]\n",
    "                    last_name = full_name[-1]\n",
    "                    faculty_data.append([first_name.strip(), last_name.strip(), email.strip(), \"\"])\n",
    "\n",
    "    elif \"westchestermedicalcenter.org\" in url:\n",
    "        # Logic for Westchester Medical Center\n",
    "        faculty_heading = soup.find(\"h2\", string=\"Faculty\")\n",
    "\n",
    "        if faculty_heading:\n",
    "            faculty_container = faculty_heading.parent\n",
    "            #print(f\"Debug (faculty_container): {faculty_container}\")\n",
    "\n",
    "            # Extract faculty information\n",
    "            faculty_data = []\n",
    "            strong_tags = faculty_container.find_all(\"strong\")  \n",
    "            for strong_tag in strong_tags:\n",
    "                split_text = strong_tag.text.split(\",\")\n",
    "                if len(split_text) > 1:\n",
    "                    full_name = split_text[0]\n",
    "                    full_name = full_name.split(\".\")\n",
    "                    if len(full_name) > 1:\n",
    "                        first_name = full_name[0] + \".\"\n",
    "                        last_name = full_name[-1]\n",
    "                        faculty_data.append([first_name.strip(), last_name.strip(), \"\", \"\"])\n",
    "                    else:\n",
    "                        full_name = split_text[0].split(\" \")\n",
    "                        first_name = full_name[0]\n",
    "                        last_name = full_name[-1]\n",
    "                        faculty_data.append([first_name.strip(), last_name.strip(), \"\", \"\"]) \n",
    "        else:\n",
    "            print(f\"Error: 'Faculty' heading not found on the {name} webpage.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Unsupported website: {url}\")\n",
    "        return\n",
    "\n",
    "    # Create a pandas DataFrame\n",
    "    df = pd.DataFrame(faculty_data)\n",
    "\n",
    "    # Set the column headers (order matters)\n",
    "    df.columns = [\"First Name\", \"Last Name\", \"Email\", \"Error\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Iterate through URLs and extract faculty data for each institution\n",
    "for institution_name, url in urls.items():\n",
    "    dfs[institution_name] = extract_faculty_data(url, institution_name)\n",
    "\n",
    "file_name = \"anesthesiology_faculty.xlsx\"\n",
    "with pd.ExcelWriter(file_name, engine='xlsxwriter') as writer:\n",
    "    # Write each DataFrame to a separate sheet in the Excel file\n",
    "    for institution_name, df in dfs.items():\n",
    "        df.to_excel(writer, sheet_name=institution_name, index=False)\n",
    "        print (f\"Saved {institution_name} data to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17750d5-9f15-43f9-8316-49d92d4ea693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
